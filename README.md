# LLM Tracer ğŸš€

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com)
[![uv](https://img.shields.io/badge/uv-package%20manager-blueviolet.svg)](https://docs.astral.sh/uv/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)

A **LangSmith-like** observability platform for LangChain and LangGraph applications. Self-hosted, open-source, and easy to deploy.

## âœ¨ Features

- **ğŸ” Full LLM Observability** - Track all LLM calls, inputs, outputs, token usage, and latency
- **ğŸ› ï¸ Tool Call Tracking** - Monitor tool/function calls with inputs, outputs, and errors
- **ğŸ“Š Beautiful Dashboard** - Waterfall view of traces with detailed inspection
- **ğŸ”‘ API Key Management** - Secure authentication for your applications
- **ğŸ“ Project Organization** - Organize traces by project
- **ğŸš€ Auto-Instrumentation** - Just call `init()` and all LangChain calls are traced automatically (like Sentry!)
- **ğŸ’¾ Self-Hosted** - Full control over your data
- **ğŸ˜ PostgreSQL + SQLite** - Production PostgreSQL with SQLite fallback for development

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Your Application                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  LangChain  â”‚â—€â”€â”€â”€â”‚   llm_tracer_sdk    â”‚                     â”‚
â”‚  â”‚     LLM     â”‚    â”‚  (auto-instrument)  â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ HTTP/API (async background)
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       LLM Tracer Server                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   FastAPI   â”‚â”€â”€â”€â–¶â”‚   Piccolo   â”‚â”€â”€â”€â–¶â”‚  PostgreSQL â”‚         â”‚
â”‚  â”‚     API     â”‚    â”‚     ORM     â”‚    â”‚  / SQLite   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                    Web Dashboard                     â”‚       â”‚
â”‚  â”‚   â€¢ Traces List  â€¢ Trace Detail  â€¢ Projects/Keys   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Project Structure

```
llm-tracer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ llm_tracer/          # Main server application
â”‚   â”‚   â”œâ”€â”€ api/             # FastAPI routes and schemas
â”‚   â”‚   â”œâ”€â”€ db/              # Database models and migrations
â”‚   â”‚   â”œâ”€â”€ templates/       # Jinja2 HTML templates
â”‚   â”‚   â”œâ”€â”€ config.py        # Application configuration
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI app entry point
â”‚   â””â”€â”€ llm_tracer_sdk/      # Client SDK for instrumentation
â”‚       â”œâ”€â”€ callback.py      # LangChain callback handler
â”‚       â”œâ”€â”€ client.py        # HTTP client for API
â”‚       â”œâ”€â”€ context.py       # Trace context management
â”‚       â”œâ”€â”€ instrumentation.py
â”‚       â””â”€â”€ sdk.py           # Main SDK interface
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ examples/                # Usage examples
â”œâ”€â”€ pyproject.toml           # Project configuration (uv/hatch)
â”œâ”€â”€ piccolo_conf.py          # Piccolo ORM configuration
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- [uv](https://docs.astral.sh/uv/) (recommended) or pip

### 1. Install uv (if not already installed)

```bash
# On macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# On Windows
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2. Clone and Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/llm-tracer.git
cd llm-tracer

# Create virtual environment and install dependencies
uv sync

# Install with development dependencies
uv sync --all-extras
```

### 3. Configure Database

```bash
# SQLite (default, no config needed)
# Just run the server!

# PostgreSQL (production)
export DATABASE_URL="postgresql://user:password@localhost:5432/llm_tracer"
# Or use individual variables:
export POSTGRES_HOST="localhost"
export POSTGRES_PORT="5432"
export POSTGRES_USER="user"
export POSTGRES_PASSWORD="password"
export POSTGRES_DB="llm_tracer"
```

### 4. Run the Server

```bash
# Using uv run
uv run llm-tracer

# Or with uvicorn directly
uv run uvicorn llm_tracer.main:app --reload --host 0.0.0.0 --port 8000

# Or using the Python module
uv run python -m llm_tracer.main
```

The server will be available at `http://localhost:8000`

### 5. Create a Project and API Key

1. Open `http://localhost:8000` in your browser
2. Go to **Projects** â†’ Create a new project
3. Go to **API Keys** â†’ Create an API key for your project
4. **Copy the API key** (it's shown only once!)

### 6. Integrate the SDK

```bash
# Install the SDK in your project
uv add llm-tracer[sdk]
# or with pip
pip install llm-tracer[sdk]
```

```python
import llm_tracer_sdk

# Initialize once at startup - that's it!
llm_tracer_sdk.init(
    api_key="lt-your-api-key",
    endpoint="http://localhost:8000"
)

# All LangChain calls are now automatically traced!
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o-mini")
response = llm.invoke("Hello!")  # <-- Automatically traced!
```

## ğŸ§ª Development

### Running Tests

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=src --cov-report=html

# Run specific test file
uv run pytest tests/test_api.py -v
```

### Linting & Formatting

```bash
# Check code with ruff
uv run ruff check src tests

# Fix auto-fixable issues
uv run ruff check --fix src tests

# Format code
uv run ruff format src tests

# Type checking with mypy
uv run mypy src
```

### Pre-commit Hooks

```bash
# Install pre-commit hooks
uv run pre-commit install

# Run on all files
uv run pre-commit run --all-files
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABASE_URL` | Full database URL | `sqlite:///./llm_tracer.db` |
| `POSTGRES_HOST` | PostgreSQL host | `localhost` |
| `POSTGRES_PORT` | PostgreSQL port | `5432` |
| `POSTGRES_USER` | PostgreSQL username | - |
| `POSTGRES_PASSWORD` | PostgreSQL password | - |
| `POSTGRES_DB` | PostgreSQL database | `llm_tracer` |
| `HOST` | Server host | `0.0.0.0` |
| `PORT` | Server port | `8000` |
| `DEBUG` | Enable debug mode | `false` |
| `SECRET_KEY` | Secret key for security | `change-me-in-production` |
| `CORS_ORIGINS` | Allowed CORS origins | `http://localhost:3000,http://localhost:8000` |

### SDK Configuration

```python
import llm_tracer_sdk

llm_tracer_sdk.init(
    api_key="lt-your-api-key",      # Required
    endpoint="http://localhost:8000", # Server URL
    debug=True,                       # Enable debug logging
)

# Set user/session context
llm_tracer_sdk.set_user("user-123")
llm_tracer_sdk.set_session("session-456")
llm_tracer_sdk.set_tags(["production", "v2"])
llm_tracer_sdk.set_metadata({"environment": "prod"})
```

## ğŸ“ Examples

See the [examples/](examples/) directory for complete usage examples:

- `basic_usage.py` - Basic auto-instrumentation
- More examples coming soon!

## ğŸ¤ Contributing

Contributions are welcome! Please read our [Contributing Guide](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspired by [LangSmith](https://smith.langchain.com/)
- Built with [FastAPI](https://fastapi.tiangolo.com/), [Piccolo ORM](https://piccolo-orm.com/), and [LangChain](https://langchain.com/)
- Package management by [uv](https://docs.astral.sh/uv/)
